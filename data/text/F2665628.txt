An official website of the European Union
How do you know?

This site uses cookies. Visit our cookies policy page or click the link in any footer for more information and to change your preferences.

Accept all cookies
Accept only essential cookies
Log in
EN
Search
Law
Feedback from: European Federation of Psychologists’ Associations (EFPA)
Have your say - Public Consultations and Feedback
Published initiatives
Artificial intelligence – ethical and legal requirements
Feedback from:
Feedback reference
F2665628
Submitted on
06 August 2021
Submitted by
Nigel Evans
User type
Other
Organisation
European Federation of Psychologists’ Associations (EFPA)
Organisation size
Micro (1 to 9 employees)
Country of origin
Belgium
Initiative
Artificial intelligence – ethical and legal requirements

EFPA, The European Federation of Psychologists (established 1981) has the mission to develop and apply psychology for a positive impact on European society and beyond. EFPA publications are regularly consulted to inform EU policy and process. Now consisting of 38 European country associations, EFPA represents almost half of the world’s Psychologists whose members are required to observe professional standards. Specifically, EFPA Board of Assessment, whose members have led on this response, convenes regularly to encourage and advance best practices in testing and assessment. 

EFPA thanks the EU Commission for their work thus far and agree the need for rules on Artificial Intelligence (AI) implementation to harness the full potential and benefits of this technology, while continuing to “put people first” in all instances. We applaud the proposal for requesting transparency and responsibility from organisations using AI.

However, we do have comments we hope are helpful as the regulations are debated:

(1)	EFPA suggests, as have several other organisations, that the risk-based approach in Title II be revised to contain more levels than the current three now proposed. This will provide better differentiation between the types of industries and organisations using AI. We agree with many of the comments that the current High-risk category is too general and needs to be more granular, so that the precautions mandated, and regulations implemented, are appropriate for the various industries engaged with AI technology. For example, psychological, occupational, health, and educational assessments have for decades utilised automated scoring processes (to minimise human error) which could be considered as “AI” technology within the current definition. However, the interpretation of the results of this scoring should only be carried out by a professional and never left to mere digital automation. 
Assessments in the field of psychology are created by scientific professionals for use by practitioners in psychology and related disciplines. We are committed to continued steps to bring attention to the importance of responsible and ethical applications. We promote this through guidelines, the distribution of publications, and presentation at conferences to encourage the highest levels of academic and practice review.

(2)	EFPA encourages care in imposing regulations for documentation on AI systems, particularly those related to assessment. Fairness and privacy are central to our work, and we regularly conduct research to ensure our assessments are fair for all individuals, particularly when used for high-stakes decisions (such as clinical diagnosis, employment, or university acceptances). We strongly adhere to the rule that assessments should always be built on the foundations of rigorous science; and would never advocate that decisions be based on one type of assessment tool (whether using AI or other process). 
Psychologists increasingly use AI technology, especially where it is shown to be beneficial to accuracy and fairness during test administration and interpretation. In these cases, many safeguards are given including: clear records of all applied methodologies and data models, employing human oversight, and monitoring against bias to foster inclusion. The regulations need to consider and reflect the current oversight and standards for fairness and privacy already utilised by psychologists.

(3)	EFPA urges regulators to hold public discussions with organisations and associations that have taken the time to provide specific feedback. These discussions can be part of your presentation to the European Parliament and Council, as the information we have provided, for example, would be critical in understanding the need for more differentiation in the guidelines. Any legislative debate would therefore be more informative for all concerned, and result in subsequent regulations that are transparent, reasonable, enforceable, and effective.

Report an issue with this feedback
All feedback

The views and opinions expressed here are entirely those of the author(s) and do not reflect the official opinion of the European Commission. The Commission cannot guarantee the accuracy of the information contained in them. Neither the Commission, nor any person acting on the Commission’s behalf, may be held responsible for the content or the information posted here. Views and opinions that violate the Commission’s feedback rules will be removed from the site.

Contact the European Commission
Follow the European Commission on social media
Resources for partners
Report an IT vulnerability
Languages on our websites
Cookies
Privacy policy
Legal notice
Accessibility